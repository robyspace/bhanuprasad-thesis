{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Deep Learning MLP for Network Intrusion Detection\n",
    "\n",
    "## CSE-CIC-IDS-2018 Dataset\n",
    "\n",
    "### üìå Why MLP Instead of LSTM?\n",
    "\n",
    "**The Problem with LSTM/CNN-LSTM:**\n",
    "- CSE-CIC-IDS-2018 contains **aggregated flow statistics** (one row = one complete flow)\n",
    "- Rows are **NOT temporally ordered** - consecutive rows are unrelated flows\n",
    "- LSTM/CNN assumes temporal sequences ‚Üí Result: **51% accuracy (random guessing)**\n",
    "\n",
    "**Why MLP Works:**\n",
    "- Treats each flow **independently** (like XGBoost/Random Forest)\n",
    "- Learns complex non-linear patterns within a single flow\n",
    "- No artificial temporal assumptions\n",
    "- Expected performance: **75-85% accuracy**\n",
    "\n",
    "### üìä Expected Performance:\n",
    "- **Target Accuracy**: 75-85%\n",
    "- **Target ROC-AUC**: 0.80-0.90\n",
    "- **Training Time**: ~5-10 minutes on GPU\n",
    "- **Inference**: Faster than LSTM, similar to XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if needed)\n",
    "# !pip install tensorflow pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DEEP LEARNING MLP FOR INTRUSION DETECTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU'))} GPU(s)\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Training will be slower on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# UPDATE THESE PATHS TO MATCH YOUR GOOGLE DRIVE STRUCTURE\n",
    "\n",
    "PROJECT_DIR = '/content/drive/MyDrive/IDS_Research'\n",
    "MODEL_DIR = f'{PROJECT_DIR}/models'\n",
    "RESULTS_DIR = f'{PROJECT_DIR}/results'\n",
    "\n",
    "# Model hyperparameters\n",
    "BATCH_SIZE = 512       # Larger batch size (no sequences = more memory available)\n",
    "EPOCHS = 50            # Maximum epochs\n",
    "LEARNING_RATE = 0.001  # Initial learning rate\n",
    "\n",
    "# Choose architecture: 'deep', 'standard', or 'lightweight'\n",
    "ARCHITECTURE = 'deep'  # Start with deep, can try others later\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Architecture: {ARCHITECTURE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 3: Load Preprocessed Data\n",
    "\n",
    "**Important:** This notebook assumes you've already run your data preprocessing.\n",
    "\n",
    "You should have:\n",
    "- `X_train_scaled`, `y_train`\n",
    "- `X_val_scaled`, `y_val`  \n",
    "- `X_test_scaled`, `y_test`\n",
    "\n",
    "If you haven't done this yet, run your ML_IDS_v4.ipynb notebook up to the preprocessing section first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed data exists\n",
    "try:\n",
    "    print(\"Checking preprocessed data...\")\n",
    "    print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "    print(f\"X_val_scaled shape: {X_val_scaled.shape}\")\n",
    "    print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "    print(f\"\\nLabel distributions:\")\n",
    "    print(f\"  Train: {np.bincount(y_train)}\")\n",
    "    print(f\"  Val:   {np.bincount(y_val)}\")\n",
    "    print(f\"  Test:  {np.bincount(y_test)}\")\n",
    "    \n",
    "    # Convert to numpy arrays if they're DataFrames\n",
    "    if isinstance(X_train_scaled, pd.DataFrame):\n",
    "        X_train = X_train_scaled.values\n",
    "        X_val = X_val_scaled.values\n",
    "        X_test = X_test_scaled.values\n",
    "    else:\n",
    "        X_train = X_train_scaled\n",
    "        X_val = X_val_scaled\n",
    "        X_test = X_test_scaled\n",
    "    \n",
    "    # Convert labels to numpy arrays if needed\n",
    "    if isinstance(y_train, pd.Series):\n",
    "        y_train = y_train.values\n",
    "        y_val = y_val.values\n",
    "        y_test = y_test.values\n",
    "    \n",
    "    print(\"\\n‚úì Data loaded successfully!\")\n",
    "    print(f\"\\nNumber of features: {X_train.shape[1]}\")\n",
    "    print(f\"Training samples: {len(X_train):,}\")\n",
    "    print(f\"Validation samples: {len(X_val):,}\")\n",
    "    print(f\"Test samples: {len(X_test):,}\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Error: Preprocessed data not found!\")\n",
    "    print(\"\\nPlease run your data preprocessing first.\")\n",
    "    print(\"You can either:\")\n",
    "    print(\"1. Run ML_IDS_v4.ipynb up to the preprocessing section\")\n",
    "    print(\"2. Or copy the preprocessing code from that notebook here\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 4: Build MLP Architecture\n",
    "\n",
    "### Key Differences from LSTM:\n",
    "- **No sequence creation** - each flow is independent\n",
    "- **Input shape**: (num_features,) instead of (time_steps, num_features)\n",
    "- **Feedforward** architecture - no recurrent connections\n",
    "- **Faster training** - no temporal dependencies to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_mlp(input_dim):\n",
    "    \"\"\"\n",
    "    Deep MLP with 5 hidden layers\n",
    "    \n",
    "    Good for:\n",
    "    - Learning complex non-linear patterns\n",
    "    - Large datasets (100K+ samples)\n",
    "    - When you have compute power available\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        \n",
    "        # Layer 1: Wide entry layer\n",
    "        layers.Dense(512, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Layer 2\n",
    "        layers.Dense(256, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Layer 3\n",
    "        layers.Dense(128, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Layer 4\n",
    "        layers.Dense(64, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Layer 5: Narrow bottleneck\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        \n",
    "        # Output\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_standard_mlp(input_dim):\n",
    "    \"\"\"\n",
    "    Standard MLP with 3 hidden layers\n",
    "    \n",
    "    Good for:\n",
    "    - Balanced performance/complexity\n",
    "    - Medium datasets (10K-100K samples)\n",
    "    - General purpose use\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        \n",
    "        layers.Dense(256, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(128, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_lightweight_mlp(input_dim):\n",
    "    \"\"\"\n",
    "    Lightweight MLP with 2 hidden layers\n",
    "    \n",
    "    Good for:\n",
    "    - Fast training/inference\n",
    "    - Small datasets (<10K samples)\n",
    "    - Resource-constrained environments\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Build selected architecture\n",
    "print(\"=\"*80)\n",
    "print(\"BUILDING MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print(f\"Input dimension: {input_dim} features\")\n",
    "print(f\"Architecture: {ARCHITECTURE}\")\n",
    "\n",
    "if ARCHITECTURE == 'deep':\n",
    "    model = build_deep_mlp(input_dim)\n",
    "elif ARCHITECTURE == 'standard':\n",
    "    model = build_standard_mlp(input_dim)\n",
    "elif ARCHITECTURE == 'lightweight':\n",
    "    model = build_lightweight_mlp(input_dim)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown architecture: {ARCHITECTURE}\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Compile Model with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = {\n",
    "    0: class_weights_array[0],\n",
    "    1: class_weights_array[1]\n",
    "}\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "print(f\"This helps handle imbalanced data (more benign than attack samples)\")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 6: Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks for better training\n",
    "callbacks_list = [\n",
    "    # Early stopping - stop if no improvement\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate when stuck\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save best model\n",
    "    callbacks.ModelCheckpoint(\n",
    "        f'{MODEL_DIR}/deep_learning_mlp_best.h5',\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=f'{PROJECT_DIR}/logs/mlp',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úì Callbacks configured:\")\n",
    "print(\"  - Early stopping (patience=10)\")\n",
    "print(\"  - Learning rate reduction (patience=5)\")\n",
    "print(\"  - Model checkpoint (save best)\")\n",
    "print(\"  - TensorBoard logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Train Model\n",
    "\n",
    "This will take 5-10 minutes on GPU, longer on CPU.\n",
    "\n",
    "**Expected behavior:**\n",
    "- Accuracy should start around 60-70% and climb to 75-85%\n",
    "- AUC should reach 0.80-0.90\n",
    "- Much better than LSTM's 51% random guessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Validation samples: {len(X_val):,}\")\n",
    "print(\"\\nTraining started...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úì TRAINING COMPLETED!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"Final training accuracy: {history.history['accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"Best validation AUC: {max(history.history['val_auc']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 8: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comprehensive training history\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Deep Learning MLP Training History', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['loss', 'accuracy', 'precision', 'recall', 'auc']\n",
    "titles = ['Loss', 'Accuracy', 'Precision', 'Recall', 'AUC']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    ax.plot(history.history[metric], label=f'Training {title}', linewidth=2)\n",
    "    ax.plot(history.history[f'val_{metric}'], label=f'Validation {title}', linewidth=2)\n",
    "    ax.set_title(f'Model {title}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate plot\n",
    "if 'lr' in history.history:\n",
    "    ax = axes[1, 2]\n",
    "    ax.plot(history.history['lr'], label='Learning Rate', linewidth=2, color='red')\n",
    "    ax.set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Learning Rate')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/mlp_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training history visualized and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 9: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Make predictions\n",
    "start_time = time.time()\n",
    "y_pred_proba = model.predict(X_test, verbose=0)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "y_pred_proba = y_pred_proba.flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "fpr_value = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "# Latency\n",
    "avg_latency = (inference_time / len(X_test)) * 1000  # ms\n",
    "\n",
    "print(f\"\\nDeep Learning MLP Test Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy*100:.2f}%\")\n",
    "print(f\"  Precision: {precision*100:.2f}%\")\n",
    "print(f\"  Recall:    {recall*100:.2f}%\")\n",
    "print(f\"  F1-Score:  {f1*100:.2f}%\")\n",
    "print(f\"  ROC-AUC:   {roc_auc:.4f}\")\n",
    "print(f\"  FPR:       {fpr_value*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  TN: {tn:>6,}  FP: {fp:>6,}\")\n",
    "print(f\"  FN: {fn:>6,}  TP: {tp:>6,}\")\n",
    "\n",
    "print(f\"\\nInference Performance:\")\n",
    "print(f\"  Avg Latency: {avg_latency:.2f} ms/sample\")\n",
    "print(f\"  Total Time:  {inference_time:.2f} seconds\")\n",
    "print(f\"  Throughput:  {len(X_test)/inference_time:.2f} samples/sec\")\n",
    "\n",
    "# Comparison with other models\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON WITH OTHER MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Failed LSTM', 'Deep MLP (This)', 'XGBoost', 'Random Forest'],\n",
    "    'Accuracy': [0.510, accuracy, 0.876, 0.877],\n",
    "    'ROC-AUC': [0.501, roc_auc, 0.951, 0.955],\n",
    "    'Latency (ms)': [114.15, avg_latency, 6.97, 36.25]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Store results\n",
    "results = {\n",
    "    'accuracy': float(accuracy),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1),\n",
    "    'roc_auc': float(roc_auc),\n",
    "    'fpr': float(fpr_value),\n",
    "    'confusion_matrix': {'tn': int(tn), 'fp': int(fp), 'fn': int(fn), 'tp': int(tp)},\n",
    "    'avg_latency_ms': float(avg_latency),\n",
    "    'training_time_seconds': float(training_time)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 10: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Benign', 'Attack'],\n",
    "            yticklabels=['Benign', 'Attack'])\n",
    "plt.title('Deep Learning MLP Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/mlp_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2.5,\n",
    "         label=f'Deep MLP (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve - Deep Learning MLP', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/mlp_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Comparison bar chart\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "models = ['Failed\\nLSTM', 'Deep\\nMLP', 'XGBoost', 'Random\\nForest']\n",
    "accuracies = [0.510, accuracy, 0.876, 0.877]\n",
    "aucs = [0.501, roc_auc, 0.951, 0.955]\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "ax1.bar(models, accuracies, color=colors)\n",
    "ax1.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.axhline(y=0.5, color='black', linestyle='--', alpha=0.3, label='Random Chance')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax2.bar(models, aucs, color=colors)\n",
    "ax2.set_title('ROC-AUC Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('ROC-AUC')\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.axhline(y=0.5, color='black', linestyle='--', alpha=0.3, label='Random Chance')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/mlp_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualizations saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 11: Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SAVING MODEL AND RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save final model\n",
    "model_path = f'{MODEL_DIR}/deep_learning_mlp_model.h5'\n",
    "model.save(model_path)\n",
    "print(f\"‚úì Model saved to: {model_path}\")\n",
    "\n",
    "# Save results as JSON\n",
    "results_dict = {\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset': 'CSE-CIC-IDS-2018',\n",
    "    'model_type': 'Deep Learning MLP (Feedforward)',\n",
    "    'architecture': ARCHITECTURE,\n",
    "    'config': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs': EPOCHS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'num_features': int(X_train.shape[1])\n",
    "    },\n",
    "    'results': results,\n",
    "    'training_samples': int(len(X_train)),\n",
    "    'validation_samples': int(len(X_val)),\n",
    "    'test_samples': int(len(X_test)),\n",
    "    'comparison_with_lstm': {\n",
    "        'lstm_accuracy': 0.510,\n",
    "        'mlp_accuracy': float(accuracy),\n",
    "        'improvement_percent': float(((accuracy - 0.510) / 0.510) * 100),\n",
    "        'lstm_auc': 0.501,\n",
    "        'mlp_auc': float(roc_auc),\n",
    "        'auc_improvement_percent': float(((roc_auc - 0.501) / 0.501) * 100)\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = f'{RESULTS_DIR}/deep_learning_mlp_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "\n",
    "print(f\"‚úì Results saved to: {results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALL DONE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nYour Deep Learning MLP model is ready for deployment!\")\n",
    "print(f\"\\nKey files saved:\")\n",
    "print(f\"  1. Model: {model_path}\")\n",
    "print(f\"  2. Results: {results_path}\")\n",
    "print(f\"  3. Visualizations: {RESULTS_DIR}/mlp_*.png\")\n",
    "\n",
    "print(f\"\\nüìä Performance Summary:\")\n",
    "print(f\"  MLP Accuracy:  {accuracy*100:.2f}% (vs LSTM: 51.0%)\")\n",
    "print(f\"  MLP ROC-AUC:   {roc_auc:.4f} (vs LSTM: 0.501)\")\n",
    "print(f\"  Improvement:   {((accuracy - 0.510) / 0.510) * 100:+.1f}% accuracy gain!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Step 12: Feature Importance Analysis (Optional)\n",
    "\n",
    "Unlike LSTM, we can analyze which features are most important using gradient-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Analyze feature importance using gradient-based methods\n",
    "# This requires the feature names from preprocessing\n",
    "\n",
    "# Uncomment if you have feature names available:\n",
    "# try:\n",
    "#     # Get weights of first layer\n",
    "#     first_layer_weights = model.layers[0].get_weights()[0]\n",
    "#     feature_importance = np.abs(first_layer_weights).mean(axis=1)\n",
    "#     \n",
    "#     # Create dataframe (you need feature_names from preprocessing)\n",
    "#     # importance_df = pd.DataFrame({\n",
    "#     #     'feature': feature_names,\n",
    "#     #     'importance': feature_importance\n",
    "#     # }).sort_values('importance', ascending=False)\n",
    "#     # \n",
    "#     # print(\"\\nTop 20 Most Important Features:\")\n",
    "#     # print(importance_df.head(20))\n",
    "#     \n",
    "# except Exception as e:\n",
    "#     print(f\"Could not compute feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Understanding Why MLP Works\n",
    "\n",
    "### Data Type Matters!\n",
    "\n",
    "**CSE-CIC-IDS-2018 Dataset:**\n",
    "- Each row = one complete network flow\n",
    "- Features = aggregated statistics (total bytes, packet count, etc.)\n",
    "- Rows are **independent** - not temporally ordered\n",
    "\n",
    "**LSTM Approach (Failed):**\n",
    "```\n",
    "Input: [flow_1, flow_2, ..., flow_10] ‚Üí Predict: flow_11\n",
    "Problem: Flows 1-10 are unrelated random flows!\n",
    "Result: 51% accuracy (random guessing)\n",
    "```\n",
    "\n",
    "**MLP Approach (Works):**\n",
    "```\n",
    "Input: [single_flow_features] ‚Üí Predict: benign or attack\n",
    "Learns: \"If bytes_sent > X AND port = 80 AND duration < Y, then benign\"\n",
    "Result: 75-85% accuracy (actual learning!)\n",
    "```\n",
    "\n",
    "### When Would LSTM Work?\n",
    "\n",
    "LSTM would be appropriate if you had:\n",
    "1. **Packet-level traces** where consecutive rows are packets from the same flow\n",
    "2. **Time-ordered logs** from a single host showing attack progression\n",
    "3. **Session sequences** tracking user behavior over time\n",
    "\n",
    "For aggregated flow statistics, MLP is the correct choice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
